<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="chrome=1">
                <title>mod_h2, a look at performance</title>
                
                <link rel="stylesheet" href="stylesheets/styles.css">
                    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
                        <link rel="stylesheet" href="stylesheets/mod_h2.css">
                            <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
                                <!--[if lt IE 9]>
                                 <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
                                 <![endif]-->
                                <script type="text/javascript"
                                    src="https://www.google.com/jsapi?autoload={
                                    'modules':[{
                                    'name':'visualization',
                                    'version':'1',
                                    'packages':['line']
                                    }]
                                    }"></script>
                                
                                <script type="text/javascript">
                                    var series        = [ '1', '2', '3', '4', '5',
                                                          '6', '7', '8', '9', '10',
                                                          '15', '20', '40', '100' ];
                                    var h2_i5_1k      = [ 11902.40, 14078.90, 15825.00, 16989.10, 17276.90, 
                                                          16739.40, 16308.00, 15776.10, 15947.30, 15654.40, 
                                                          15972.10, 15997.30, 16214.00, 16581.00 ];
                                    var h2_i5_2k      = [ 11438.60, 13624.00, 15529.60, 16697.60, 16482.60, 
                                                          16403.20, 16075.40, 15649.20, 15373.10, 15307.10, 
                                                          15465.00, 15703.40, 16008.50, 16377.10 ];
                                    var h2_i5_4k      = [ 10662.10, 12500.40, 13939.90, 13655.30, 13664.40, 
                                                          13869.00, 13894.40, 13917.20, 13994.00, 13972.50, 
                                                         14231.10, 14282.40, 14528.10, 14759.20 ];
                                    var h2_i5_7k      = [ 9903.40, 11324.40, 11643.20, 11784.00, 11875.80, 
                                                          11986.20, 12077.20, 12071.80, 12140.30, 12262.80, 
                                                          12378.20, 12423.20, 12468.30, 12594.20 ];
                                    var h2_i5_10k     = [ 9268.10, 9895.70, 10179.10, 10201.10, 
                                                          10236.60, 10258.20, 10287.70, 10275.40, 10275.40, 
                                                          10285.50, 10290.90, 10278.60, 10271.60, 10069.30 ];
                                    var h2_i7_7k      = [ 14615, 14473, 14411, 14180, 14170, 
                                                          14580, 15042, 15143, 14672, 14438, 
                                                          14626, 14282, 14983, 14811];
                                    var h2_i7_1k      = [ 16261, 28623, 28562, 27193, 27294, 
                                                          27008, 26814, 26373, 26252, 26657, 
                                                          27592, 27638, 27825, 28212];
                                    var max_1gbps_7k  = [ 16231, 16231, 16231, 16231, 16231, 
                                                          16231, 16231, 16231, 16231, 16231, 
                                                          16231, 16231, 16231, 16231];
                                    var max_1gbps_10k = [ 11286, 11286, 11286, 11286, 11286, 
                                                          11286, 11286, 11286, 11286, 11286,
                                                          11286, 11286, 11286, 11286];
                                     var wrk_7k =[ 8519, 8519, 8519, 8519, 8519, 
                                                   8519, 8519, 8519, 8519, 8519, 
                                                   8519, 8519, 8519, 8519 ];
                                                          

                                    function addSeries(table, options, typename, title, data, color) {
                                        var n = table.getNumberOfColumns();
                                        
                                        table.addColumn(typename, title);
                                        if (n) {
                                            for (var i = 0; i < data.length; ++i) {
                                                table.setCell(i, n, data[i]);
                                            }
                                        }
                                        else {
                                            var rows = [];
                                            for (var i = 0; i < data.length; ++i) {
                                                rows.push([data[i]]);
                                            }
                                            table.addRows(rows);
                                        }
                                        
                                        if (color) {
                                            var colors = options.colors || [];
                                            colors.push(color);
                                            options.colors = colors;
                                        }
                                    }
                                
                                    google.setOnLoadCallback(drawCharts);
                                    
                                    function drawCharts() {
                                        var data = new google.visualization.DataTable();
                                        var options = {
                                            chart: {
                                                title: 'mod_h2 size and parallelism',
                                                subtitle: 'requests/second on a 1Gbps ethernet, for various resource sizes'
                                            },
                                            legend: { position: 'bottom' }
                                        };
                                        addSeries(data, options, 'string', '# of parallel requests', series);
                                        addSeries(data, options, 'number', 'mod_h2, 1024 bytes',     h2_i5_1k, '#90cc00');
                                        addSeries(data, options, 'number', 'mod_h2, 2005 bytes',     h2_i5_2k, '#a0cc60');
                                        addSeries(data, options, 'number', 'mod_h2, 4310 bytes',     h2_i5_4k, '#b0cc90');
                                        addSeries(data, options, 'number', 'mod_h2, 7526 bytes',     h2_i5_7k, '#4444aa');
                                        addSeries(data, options, 'number', '1 Gbps Ethernet, 7.5k',  max_1gbps_7k, '#9999ff');
                                        addSeries(data, options, 'number', 'wrk, http/1, 7.5k',      wrk_7k, '#ddddff');
                                        addSeries(data, options, 'number', 'mod_h2, 10844 bytes',    h2_i5_10k, '#bd8047');
                                        addSeries(data, options, 'number', '1 Gbps Ethernet, 10k',   max_1gbps_10k, '#bda087');
                                        
                                        var chart = new google.charts.Line(document.getElementById('chart_1'));
                                        chart.draw(data, options);
                                        

                                        data = new google.visualization.DataTable();
                                        options = {
                                            chart: {
                                                title: 'mod_h2 size and power',
                                                subtitle: 'requests/second on a 1Gbps ethernet, CPU power differences'
                                            },
                                            legend: { position: 'bottom' }
                                        };
                                        addSeries(data, options, 'string', '# of parallel requests', series);
                                        addSeries(data, options, 'number', 'mod_h2, i5 2010, 1k',    h2_i5_1k, '#90cc00');
                                        addSeries(data, options, 'number', 'mod_h2, i7 2012, 1k',    h2_i7_1k, '#b0ff00');
                                        addSeries(data, options, 'number', 'mod_h2, i5 2010, 7.5k',  h2_i5_7k, '#4444aa');
                                        addSeries(data, options, 'number', '1 Gbps Ethernet, 7.5k',  max_1gbps_7k, '#9999ff');
                                        addSeries(data, options, 'number', 'mod_h2, i7 2012, 7.5k',  h2_i7_7k, '#222288');
                                                      
                                        var chart2 = new google.charts.Line(document.getElementById('chart_2'));
                                        chart2.draw(data, options);
                                    }
                                </script>
                                
                                </head>
    <body>
        <div class="wrapper">
            <div class="backlogo">
                <a href="https://github.com/icing/mod_h2/releases">Available Releases on GitHub</a>
            </div>
            <header>
                <h1>mod_h2</h1>
                <p>HTTP/2 module for Apache httpd</p>
                
                <ul>
                    <li><a href="https://github.com/icing/mod_h2/zipball/master">Download <strong>ZIP File</strong></a></li>
                    <li><a href="https://github.com/icing/mod_h2/tarball/master">Download <strong>TAR Ball</strong></a></li>
                    <li><a href="https://github.com/icing/mod_h2">View On <strong>GitHub</strong></a></li>
                </ul>
            </header>
            <section>
                <h1>
                    <a id="mod_h2---a-http2-modules-for-apache-httpd" class="anchor" href="#top" aria-hidden="true"><span class="octicon octicon-link"></span></a>mod_h2, a look at performance</h1>
                
                <p>Copyright (C) 2015 greenbytes GmbH</p>
                
                <p>Copying and distribution of this file, with or without modification,
                are permitted in any medium without royalty provided the copyright
                notice and this notice are preserved.  This file is offered as-is,
                without warranty of any kind. See LICENSE for details.</p>
                
                <h2><a id="par-pwr" class="anchor" href="#par-pwr" aria-hidden="true"><span class="octicon octicon-link"></span></a>
                    Parallelism and Power<div class="post-date">2015-06-19</div>
                </h2>
                <p>
                I did some measurements between two machines linked with a 1 Gbps ethernet to see what the effect of requested
                resource size played with the number of parallel streams. Some surprises.
                </p><p>
                A 1 Gbps ethernet can theoretically carry 81000 full 1518 byte frames per second 
                (<a href="http://rickardnobel.se/actual-throughput-on-gigabit-ethernet/">source</a>) which gives a max throughput 
                of 122958000 bytes or 117 MB/sec. <br>
                When transferring a resource of 10844 bytes 500000 times, this amounts to 5422000000 bytes or 5170 MB. Of payload. 
                <code>h2load</code> reports that 25063966 bytes were transferred additionally, so about 24 MB, short of 5%. This
                gives a theoretical maximum of 44.3 seconds to transfer this amount of data. Or, broken down by the 500000 requests,
                a maximum of 11286 requests/second.
                </p><p>
                Similarly, for the resource with 7526 bytes, h2load transferred 3787560677 bytes in total. Which gives a theoretical
                maximum of 16231 requests/second.
                </p><p>
                <div id="chart_1" class="chart"></div>
                </p><p> 
                For the 10k resource, <code>mod_h2</code> comes close to the maximum throughput. For 7k resources, not so much. Compared
                to the <code>HTTP/1.1</code> measurements using <code><a href="https://github.com/wg/wrk">wrk</a></code>, the module looks
                    fine (there is suspicion that wrk and h2load are not directly comparablem though).
                </p><p> 
                As resource sizes become smaller and smaller, there is a peculiar <em>wave</em> effect. When using more than 4-5 requests
                in parallel, performance gets worse and recovers slowly with every increasing parallelism. What is going on here?
                </p><p> 
                This became clearer when I swapped the server test machine, a iMac i5 2010 with my Powerbook i7 2012:
                </p><p>
                <div id="chart_2" class="chart"></div>
                </p><p>
                This leads me to the following observations:
                <ul>
                    <li><code>h2</code> performance for small resources is superior to <code>h1</code>, even if no parallel requests
                    are made. The binary format and header compression pays off.</li>
                    <li><code>h2</code> parallelism burns server CPU cycles and is not for free. This - currently - is visible when
                    requesting very small resources and performance <em>decreases</em> with more parallelism. (This is the current
                        theory on the measured 'wave', it may be an implementation issue.)</li>
                    <li>With the dual core i5 from 2010, we can fill up the 1Gpbs pipe with 10k resources. The larger the resources,
                    the easier it will be. With a quad core i7, we can achieve the same for 7.5 k sized resources (All on 100 simultaneous, busy
                        connections). It works.</li>
                    <li>If you consider implementing a large <code>h2</code> client, the tradeoff/benefit in number of connections used
                    vs. number of parallel requests is not easily answered. Putting all actions into a single connection will run
                    into multi-threading overhead for any implementation out there. The "at least 100" parallel streams
                    a server should offer needs more thought.</li>
                    <li>The less CPU cycles a server burns per request, the better. But this is old news, since it was already true for <code>h1</code>. For <code>mod_h2</code> there are several areas where optimizations are still possible. More effort is needed (Time &amp; Brains).</li>
                </ul>
                </p>
                
                <h2><a id="large-transfers" class="anchor" href="#large-transfers" aria-hidden="true"><span class="octicon octicon-link"></span></a>
                    Large Transfers<div class="post-date">2015-05-12</div>
                </h2>
                <p>
                With release <code>v0.5.5</code> <code>mod_h2</code> addresses performance of writes. Early tests in April showed that transfers
                of large resources achieved only 50-60% of the throughput that was possible with HTTP/1.1, e.g. httpd not involving mod_h2 (on my
                machine, all over https). That seemed excessively slow.
                </p>
                <p>
                At first I suspected that the code just did not shovel the data fast enough from worker threads to the main connection. But
                changes there resulted in only marginal improvements.
                </p>
                <p>
                Then I looked at how mod_h2 actually passed the raw HTTP/2 frames down the httpd filter chain for writing to the connection. I 
                experimented with some simple write buffering and immediately got much better results. So I looked at how connection output
                filters work with the data they are given, especially the output filter from <code>mod_ssl</code>.
                </p>
                <p>
                For those unfamiliar with the httpd internals: the server uses a very nice mechanism call <em>bucket brigades</em> for
                input and output handling. A very smart list of data chunks, basically, that allows also for meta data buckets like
                flushing, end-of-stream or resource maintenance indicators. The main purpose of <em>brigades</em> is to make copying of
                data <em>chunks</em> unnecessary for most operations on the overall data <em>stream</em>. This way, code can manage a brigade
                of a 10 MB file without having the full 10 MB in memory, read the first 16 KB of it, insert a flush bucket any time etc.
                without copying of data from one buffer to another.
                </p>
                <p>
                <code>mod_h2</code> gets complete frames from its <code>nghttp2</code> engine to be transfered to the client. Before <code>v0.5.5</code> it placed them
                into a bucket and passed that down the connection output filter chain where it eventually reached <code>mod_ssl</code>'s
                filter, got encrypted and then passed to the socket. While DATA frames are mostly 8-16 KB in size, depending on the amount
                delivered by the worker threads, there are also may other session management frames that are quite small.
                </p>
                <p>
                By just passing these small frames as buckets in the output brigade, <code>mod_ssl</code> was doing a <code>SSLWrite()</code> on
                each of them, including all the yadayada that is required by TLS. And this was causing the slow performance.
                </p>
                <p>
                <code>v0.5.5</code> uses <code>apr_brigade_write()</code> instead, which contains some very smart code. If possible, it collects
                small data chunks into 8 KB buckets and, given a proper flush callback, directly writes large data chunks without
                copying. That gives the following measurements on my Ubuntu image, transferring a 10 MB file 1000 times via 8 connections:
                </p>
                <table>
                    <thead>
                        <tr><th>Scenario</th><th>Metric</th><th>/005.txt</th></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>wrk (http/1.1)</td><td>MB/s</td><td class="num"> 1029 </td>
                        </tr>
                        <tr>
                            <td>mod_h2(0.5.4)</td><td>MB/s</td><td class="num"> 601 </td>
                        </tr>
                        <tr>
                            <td>mod_h2(0.5.5)</td><td>MB/s</td><td class="num"> 950 </td>
                        </tr>
                    </tbody>
                </table>
                <p>
                With this change, <code>mod_h2</code> is transferring data about as fast as in HTTP/1.1 and there is no downside of
                enabling HTTP/2 in a httpd that needs to transfer large resources<sup>*)</sup>.
                </p>
                <p class="fn">
                <sup>*)</sup>In my test scenarios. If you have proof to the contrary, please submit a test case!
                </p>
                
                
                
                <h2><a id="tests" class="anchor" href="#tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>
                    Parallelism<div class="post-date">2015-04-15</div>
                </h2>
                <p>
                With release <code>v0.5.0</code> I did some improvements internally that reflect in less memory
                consumptiona and better performance. I also did a detailed look at the effect that parallel stream
                numbers have on the overall results.
                </p>
                <p>
                The tests were again done on my trustworthy MacBook with a Parallels (hah!) Ubuntu 14.04 image. All tests
                ran in the sandbox. The numbers are samples from several runs, not really averaged and with variation
                and all that stuff that I should know and do as a mathematician...but I want just to give a feel
                for it.
                </p>
                <table>
                    <thead>
                        <tr><th>Scenario</th><th>Parallelism</th><th>Metric</th><th>/index.html</th></tr>
                        <tr><th>        </th><th>           </th><th>      </th><td class="num"> 653 bytes </td></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>wrk (httpd 2.4.12)</td><td><code> - </code></td><td>req/s</td><td class="num"> 26026 </td>
                        </tr>
                        <tr>
                            <td>nghttpd(0.7.11)</td><td><code>-m 1</code></td><td>req/s</td><td class="num"> 23691 </td>
                        </tr>
                        <tr>
                            <td>  </td><td><code>-m 10</code></td><td>req/s</td><td class="num"> 71078 </td>
                        </tr>
                        <tr>
                            <td>  </td><td><code>-m 20</code></td><td>req/s</td><td class="num"> 84392 </td>
                        </tr>
                        <tr>
                            <td>  </td><td><code>-m 40</code></td><td>req/s</td><td class="num"> 89725</td>
                        </tr>
                        <tr>
                            <td> </td><td><code>-m 100</code></td><td>req/s</td><td> ~30% failures</td>
                        </tr>
                        <tr>
                            <td>mod_h2(0.5.0)</td><td><code>-m 1</code></td><td>req/s</td><td class="num"> 19587 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 2</code></td><td>req/s</td><td class="num"> 23702 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 5</code></td><td>req/s</td><td class="num"> 28582 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 10</code></td><td>req/s</td><td class="num"> 28723 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 20</code></td><td>req/s</td><td class="num"> 29535 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 40</code></td><td>req/s</td><td class="num"> 29189 </td>
                        </tr>
                        <tr>
                            <td>   </td><td><code>-m 100</code></td><td>req/s</td><td class="num"> 29498 </td>
                        </tr>
                    </tbody>
                </table>
                <p>
                Interpretation? I think it is safe to say the following:
                <ul>
                    <li>The <code>-m 1</code> numbers show that the cost of a single request is still 20% higher 
                        in <code>mod_h2</code> compared to <code>nghttpd</code>.</li>
                    <li>The overall performance of HTTP/2 is better than HTTP/1 if the number of parallel requests
                        exceeds 2-5, depending on implementation.</li>
                    <li>The scaling of the <code>nghttpd</code> is fabulous, however the <code>-m 100</code> case shows
                        that it keeps files open until streams are done and runs out of file handles rather soon. (I am sure
                        now that I mentioned it that the next nghttp2 release will fix this and keep the performance, too!).</li>
                    <li><code>mod_h2</code> hits is ceiling with 10-20 parallel streams very soon. But the good news is it
                        stays stable with increased stream numbers. </li>
                </ul>
                <code>mod_h2</code> stays stable with increasing parallel stream numbers because files for static content
                get converted into byte buffers before worker threads turn to other streams. That limits the number of
                open files to the number of worker threads. 
                </p>
                <p>
                This is a compromise in the current processing model. The HTTP/2 connection terminates in a specific 
                worker process and that process has a limit on the number of open files. No spawning of new processes
                will really help the connection. If HTTP/2 connections should expose long lifetimes and bursty, parallel
                streams, resources need to be allocated carefully.
                </p>
                <p>
                The <code>v0.5.0</code> release allocates everything for stream handling per worker. The worker has a
                memory pool, bucket allocators and pseudo connection socket and rents those out to the stream that it
                processes. The stream is done, if all its output data has been sent or sits in the, size limited, output
                buffers of the HTTP/2 session. So, opening a new stream will allocate only a few bytes. Only when processing
                of the stream actually starts will more resources be allocated, most of them on hot standby in the worker
                itself. Therefore the stable performance with increasing parallel stream numbers.
                </p>
                
                <h2><a id="tests" class="anchor" href="#tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>
                    Tests<div class="post-date">2015-04-02</div>
                </h2>
                
                <p><em style="font-weight: bold; font-size: 14pt;">Important update below!</em>
                </p>
                <p>
                I did two tests in three combinations, using the <code>mod_h2</code> sandbox setup on an Ubuntu Parallels Image. 
                I used <code>h2load</code> for the HTTP/2 test cases and the nice <code>wrk</code> (see <a href="https://github.com/wg/wrk">https://github.com/wg/wrk</a>) for the HTTP/1.1 numbers.
                </p>
                <p>
                The performance tests invoked were:
                <pre><code>
                    wrk wrk -t10 -c100 -d30s https://test.example.org:12346/&lt;file&gt;
                    h2load -c 100 -t 10 -n 740000 https://test.example.org:12346/&lt;file&gt;
                </code></pre>
                where wrk was tested against Apache httpd 2.4.12 with TLS+http/1.1 and h2load was tested
                with <code>nghttpd</code>, the server that comes with nghttp2, and mod_h2 in the Apache httpd 2.4.12 setup.
                <code>test.example.org</code> was mapped to <code>127.0.0.1</code>.
                </p>
                <p>
                The numbers:
                <table>
                    <thead>
                        <tr><th>Scenario</th><th>Metric</th><th>/index.html</th><th>/002.jpg</th></tr>
                        <tr><th>        </th><th>      </th><td class="num"> 653 bytes </td><td class="num"> 90364 bytes</td></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>wrk + apache(2.4.12)</td><td>req/s</td><td class="num"> 25139 </td><td class="num"> 7941 </td>
                        </tr>
                        <tr>
                            <td></td><td>MB/s</td><td class="num"> 23.1 </td><td class="num"> 686.8 </td>
                        </tr>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td>req/s</td><td class="num"> 25084 </td><td class="num"> 4022 </td>
                        </tr>
                        <tr>
                            <td></td><td>MB/s</td><td class="num"> 16.3 </td><td class="num"> 347.0 </td>
                        </tr>
                        <tr>
                            <td>h2load + mod_h2(0.4.3)</td><td>req/s</td><td class="num"> 16093 </td><td class="num"> 4272 </td>
                        </tr>
                        <tr>
                            <td></td><td>MB/s</td><td class="num"> 10.7 </td><td class="num"> 368.7 </td>
                        </tr>
                    </tbody>
                </table>
                </p>
                
                <h2><a id="discuss" class="anchor" href="#discuss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Discussion</h2>
                <p>How to interpret this? Like every benchmark: with care.
                </p>
                <p>First of all <code>wrk</code> and <code>h2load</code> are different programs and its dangerous to compare the absolute numbers between them. But assuming that they are both as efficient in generating the load, one can see that the number of requests generated per second is very similar between <code>wrk</code> and <code>h2load+nghttpd</code>. The MB/s shows either the effect of header compression, or that both tools measure throughput differently. But my bet is on header compression. index.html is very small and compression will play a larger role.
                </p>
                <p>The <code>mod_h2</code> performance is at about two thirds now (coming from a good 50% start in February) of that of <code>nghttpd</code> or http/1.1 Apache. This is the penalty that <code>mod_h2</code> has to pay currently in processing individual requests via the Apache <code>httpd</code> 2.4.x runtime. It internally has to fake HTTP/1.1 requests and parse HTTP/1.1 responses and that costs time and resources. The advantage of adding HTTP/2 support without changing the Apache core itself.
                </p>
                <p>That <code>mod_h2</code>'s implementation is not inherently stupid becomes visible when looking at requests for the larger resource. In this scenario, the i/o optimized Apache <code>httpd</code> can really shine. Since most of the power goes into shoveling a large file onto a socket and ramming it down TCP's flow control throat, we see almost twice the performance of <code>nghttpd/mod_h2</code>.
                </p>
                <p>
                Some people might suspect that the lower performance is a inherent disadvantage of HTTP2 flow control. However if one looks at <a href="https://github.com/h2o/h2o">performance measurements from the h2o server</a>, one sees that HTTP/2 performance in throughput and requests/s can match and even outpace HTTP/1 implementations.
                </p>
                <p>So, the most likely suspect (and that needs to be investigated more) is the way that <code>nghttp2</code> and <code>mod_h2</code> handle response <code>DATA</code>. There are two points to make:
                <ul>
                    <li><code>libnghttp2</code> uses a <code>dataprovider</code> callback API that needs to return a memory buffer with the data. It then shuffles this data around internally until it is read to send it out (properly framed). This means that static files (mmap'ed) will be copied at least twice. In comparison, the Apache <code>bucket brigade</code> architecture will do this only once and in a very efficient manner.</li>
                    <li>the additional work that <code>mod_h2</code> does when collecting response DATA from different threads and feeding it to <code>nghttp2</code> does not limit performance (in this case). This seems to be the benefit of having own data bucket structures that are passed between threads without copying.</li>
                </ul>
                </p>
                <p>
                Anyway, those are the two area to work on: data copying and Apache core integration. There's probably a lot of fun ahead. Feedback always welcome.
                </p>
                
                
                <h2><a id="update" class="anchor" href="#update" aria-hidden="true"><span class="octicon octicon-link"></span></a>Update</h2>
                <p>
                And feedback I got: Tatsuhiro Tsujikawa (the author of nghttp2) pointed out that <code>h2load</code> without the 
                <code>-m number</code> option will only send one request at a time per connection. Doh! How could I miss that?
                </p>
                <p>
                In the light of this, my numbers above are a comparision what you get if you use HTTP/2 <em>exactly</em> as HTTP/1.1. But if
                you really start to send requests in parallel, I get much nicer numbers for the small requests:
                <table>
                    <thead>
                        <tr><th>Scenario</th><th>Parallelism</th><th>Metric</th><th>/index.html</th></tr>
                        <tr><th>        </th><th>           </th><th>      </th><td class="num"> 653 bytes </td></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td><code>-m 10</code></td><td>req/s (MB/s)</td><td class="num"> 67157 (43.7)</td>
                        </tr>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td><code>-m 20</code></td><td>req/s (MB/s)</td><td class="num"> 81847 (53.2)</td>
                        </tr>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td><code>-m 30</code></td><td>req/s (MB/s)</td><td class="num"> 85494 (55.6)</td>
                        </tr>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td><code>-m 40</code></td><td>req/s (MB/s)</td><td class="num"> 87312 (56.8)</td>
                        </tr>
                        <tr>
                            <td>h2load + nghttpd(0.7.9)</td><td><code>-m 50</code></td><td>req/s (MB/s)</td><td class="num"> 88216 (57.4)</td>
                        </tr>
                        <tr>
                            <td>h2load + mod_h2(0.4.3)</td><td><code>-m 10</code></td><td>req/s</td><td class="num"> 25575 (17.1)</td>
                        </tr>
                        <tr>
                            <td>h2load + mod_h2(0.4.3)</td><td><code>-m 20</code></td><td>req/s</td><td class="num"> 26553 (17.8)</td>
                        </tr>
                        <tr>
                            <td>h2load + mod_h2(0.4.3)</td><td><code>-m 30</code></td><td>req/s</td><td class="num"> 24952 (16.7)</td>
                        </tr>
                    </tbody>
                </table>
                And there it seems to peek quite early with parallelism in <code>mod_h2</code>, while <code>nghttp2</code> blazes ahead! 
                My apologies to Tatsuhiro for the earlier numbers and the wrong impression reported!
                </p>
                <p>Well, next week I need to look while <code>mod_h2</code> does not scale better, it seems.
                </p>
                <p>Münster, 02.04.2015,</p>
                
                <p>Stefan Eissing, greenbytes GmbH</p>
            </section>
            <footer>
                <p>This project is maintained by <a href="https://github.com/icing">icing</a></p>
                <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
            </footer>
        </div>
        <script src="javascripts/scale.fix.js"></script>
        
    </body>
</html>
